{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "npyXveMbbU7t"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sQgnmKdHHB92"
      },
      "outputs": [],
      "source": [
        "LATENT_DIM = 100\n",
        "OUTPUT_DIM = 3\n",
        "IMG_HEIGHT = 64\n",
        "IMG_WIDTH = 64\n",
        "BATCH_SIZE = 128\n",
        "N_EPOCH = 1\n",
        "N_CRITIC = 5\n",
        "LAMBDA = 10\n",
        "FIXED_SEED = 1729\n",
        "\n",
        "INITIAL_EPOCH = 0\n",
        "LOSS_G = []\n",
        "LOSS_C = []\n",
        "FIXED_NOISE = tf.random.normal([36, 1, 1, LATENT_DIM])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyjaMF-5JXMI",
        "outputId": "868d5f03-3096-471e-f612-3020c408533e"
      },
      "outputs": [],
      "source": [
        "THIS_DIR = ''\n",
        "\n",
        "PROJECT_DIR = os.path.join(THIS_DIR, 'WGAN_GP/')\n",
        "DATASET_DIR = os.path.join(THIS_DIR, 'datasets', 'waifu')\n",
        "\n",
        "OUTPUT_DIR = os.path.join(PROJECT_DIR, 'output/')\n",
        "CHECKPOINT_DIR = os.path.join(PROJECT_DIR, 'checkpoint/')\n",
        "STATE_FILE_PATH = os.path.join(PROJECT_DIR, 'state_file')\n",
        "\n",
        "if not os.path.exists(PROJECT_DIR):\n",
        "  os.makedirs(PROJECT_DIR)\n",
        "if not os.path.exists('datasets'):\n",
        "  os.makedirs('datasets')\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "  os.makedirs(OUTPUT_DIR)\n",
        "if not os.path.exists(CHECKPOINT_DIR):\n",
        "  os.makedirs(CHECKPOINT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-TzfhCpYHlXh"
      },
      "outputs": [],
      "source": [
        "class Generator(keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.w_init = tf.random_normal_initializer(mean=0.0, stddev=0.02, seed=FIXED_SEED)\n",
        "        self.model = keras.Sequential([\n",
        "            keras.layers.Conv2DTranspose(512, (4, 4), strides=(1, 1), padding='valid', use_bias=False, kernel_initializer=self.w_init, input_shape=(1, 1, LATENT_DIM), data_format='channels_last'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.ReLU(),\n",
        "\n",
        "            keras.layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=self.w_init),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.ReLU(),\n",
        "\n",
        "            keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=self.w_init),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.ReLU(),\n",
        "\n",
        "            keras.layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=self.w_init),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.ReLU(),\n",
        "\n",
        "            keras.layers.Conv2DTranspose(OUTPUT_DIM, (4, 4), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=self.w_init, activation='tanh'),\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.model(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NBoRMVmjHyzv"
      },
      "outputs": [],
      "source": [
        "class Critic(keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Critic, self).__init__()\n",
        "        self.w_init = tf.random_normal_initializer(mean=0.0, stddev=0.02, seed=FIXED_SEED)\n",
        "        self.model = keras.Sequential([\n",
        "            keras.layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', kernel_initializer=self.w_init, input_shape=(IMG_HEIGHT, IMG_WIDTH, OUTPUT_DIM), data_format='channels_last'),\n",
        "            keras.layers.LeakyReLU(0.2),\n",
        "\n",
        "            keras.layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=self.w_init),\n",
        "            keras.layers.LeakyReLU(0.2),\n",
        "\n",
        "            keras.layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same', kernel_initializer=self.w_init),\n",
        "            keras.layers.LeakyReLU(0.2),\n",
        "\n",
        "            keras.layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same', kernel_initializer=self.w_init),\n",
        "            keras.layers.LeakyReLU(0.2),\n",
        "\n",
        "            keras.layers.Conv2D(1, (4, 4), strides=(1, 1), padding='valid', kernel_initializer=self.w_init, activation='linear'),\n",
        "            keras.layers.Flatten(),\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.model(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b3n80kkMH5L6"
      },
      "outputs": [],
      "source": [
        "class WGAN_GP(keras.Model):\n",
        "    def __init__(self, generator, critic):\n",
        "        super(WGAN_GP, self).__init__()\n",
        "        self.generator = generator\n",
        "        self.critic = critic\n",
        "\n",
        "    def compile(self, gen_optimizer, crit_optimizer):\n",
        "        self.gen_optimizer = gen_optimizer\n",
        "        self.crit_optimizer = crit_optimizer\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, img_batchs):\n",
        "        # train critic n_critic times\n",
        "        for img_batch in img_batchs:\n",
        "            batch_size = img_batch.shape[0]\n",
        "            noise = tf.random.normal([batch_size, 1, 1, LATENT_DIM])\n",
        "            epsilon = tf.random.uniform(shape=[batch_size, 1, 1, 1], minval=0, maxval=1)\n",
        "\n",
        "            with tf.GradientTape() as crit_tape:\n",
        "                with tf.GradientTape() as gp_tape:\n",
        "                    generated_imgs = self.generator(noise, training=True)\n",
        "                    interpolated_imgs = epsilon * img_batch + (1-epsilon) * generated_imgs\n",
        "                    interpolated_imgs_pred = self.critic(interpolated_imgs, training=True)\n",
        "\n",
        "                grads = gp_tape.gradient(interpolated_imgs_pred, interpolated_imgs)\n",
        "                grad_norms = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
        "                gradient_panelty = tf.reduce_mean(tf.square(grad_norms - 1))\n",
        "\n",
        "                fx = self.critic(img_batch, training=True)\n",
        "                fgz1 = self.critic(generated_imgs, training=True)\n",
        "                crit_loss = tf.reduce_mean(fgz1) - tf.reduce_mean(fx) + LAMBDA * gradient_panelty\n",
        "\n",
        "            crit_gradients = crit_tape.gradient(crit_loss, self.critic.trainable_variables)\n",
        "            self.crit_optimizer.apply_gradients(zip(crit_gradients, self.critic.trainable_variables))\n",
        "\n",
        "        # train generator 1 time\n",
        "        noise = tf.random.normal([BATCH_SIZE, 1, 1, LATENT_DIM])\n",
        "        with tf.GradientTape() as gen_tape:\n",
        "            generated_imgs = self.generator(noise, training=True)\n",
        "            fgz2 = self.critic(generated_imgs, training=True)\n",
        "            gen_loss = -tf.reduce_mean(fgz2)\n",
        "\n",
        "        gen_gradients = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "        self.gen_optimizer.apply_gradients(zip(gen_gradients, self.generator.trainable_variables))\n",
        "\n",
        "        return gen_loss, crit_loss, fx, fgz1, fgz2\n",
        "\n",
        "    def train(self, dataset, n_epoch, n_critic, fixed_noise):\n",
        "        dataset = list(dataset)\n",
        "        n_batch = len(dataset)\n",
        "        n_iter = n_batch // n_critic\n",
        "\n",
        "        for epoch in range(1, n_epoch+1):\n",
        "            iter = 0\n",
        "            for i in range(0, n_batch, n_critic):\n",
        "                img_batchs = dataset[i:i+n_critic]\n",
        "                gen_loss, crit_loss, fx, fgz1, fgz2 = self.train_step(img_batchs)\n",
        "                LOSS_G.append(gen_loss.numpy())\n",
        "                LOSS_C.append(crit_loss.numpy())\n",
        "                iter += 1\n",
        "\n",
        "            if epoch % 10 == 0 or epoch == n_epoch:\n",
        "                fx = tf.reduce_mean(fx)\n",
        "                fgz1 = tf.reduce_mean(fgz1)\n",
        "                fgz2 = tf.reduce_mean(fgz2)\n",
        "                print(f'epoch {epoch+INITIAL_EPOCH}/{n_epoch+INITIAL_EPOCH} \\t iteration {iter+1}/{n_iter} \\t loss_g {gen_loss:.4f} \\t loss_c {crit_loss:.4f} \\t fx {fx:.4f} \\t fgz1 {fgz1:.4f} \\t fgz2 {fgz2:.4f}')\n",
        "\n",
        "                # save image\n",
        "                generated_imgs = self.generator(fixed_noise, training=False)\n",
        "                generated_imgs = (generated_imgs + 1) * 127.5 # convert back to [0, 255]\n",
        "\n",
        "                plt.figure(figsize=(10, 10))\n",
        "                for a in range(36):\n",
        "                    plt.subplot(6, 6, a+1)\n",
        "                    plt.xticks([])\n",
        "                    plt.yticks([])\n",
        "                    plt.grid(False)\n",
        "                    plt.imshow(generated_imgs[a].numpy().astype(np.uint8))\n",
        "                plt.savefig(OUTPUT_DIR + f'epoch{epoch+INITIAL_EPOCH}iteration{iter+1}.png', bbox_inches='tight')\n",
        "                plt.close('all')\n",
        "\n",
        "                # save weight\n",
        "                self.save_weights(CHECKPOINT_DIR + f'wgan_gp')\n",
        "\n",
        "                # save state\n",
        "                state_file = open(STATE_FILE_PATH, 'wb')\n",
        "                pickle.dump({\n",
        "                    'LATEST_EPOCH': epoch+INITIAL_EPOCH,\n",
        "                    'LOSS_G': LOSS_G,\n",
        "                    'LOSS_C': LOSS_C,\n",
        "                    'FIXED_NOISE': FIXED_NOISE\n",
        "                }, state_file)\n",
        "                state_file.close()\n",
        "\n",
        "    def generate_image_and_save(self, filename):\n",
        "        noise = tf.random.normal([1, 1, 1, LATENT_DIM])\n",
        "        generated_img = self.generator(noise, training=False)[0]\n",
        "        generated_img = (generated_img + 1) * 127.5 # convert back to [0, 255]\n",
        "        keras.utils.save_img(filename, generated_img, data_format='channels_last')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "\n",
        "DATASET_URL = {\n",
        "    'butterfly': 'https://drive.google.com/file/d/16hvG9aHAkKQ_uWR4Un7iod8Gx3Q5_SWQ/view?usp=share_link',\n",
        "    'waifu': 'https://drive.google.com/file/d/1Ai6djAgUlvLl-t64k_esclMyYfXNllgw/view?usp=share_link'\n",
        "}\n",
        "\n",
        "\n",
        "def download(dataset_name, datasets_dir):\n",
        "    if not dataset_name in DATASET_URL:\n",
        "        raise Exception('dataset not found.')\n",
        "    \n",
        "    if not os.path.exists(datasets_dir):\n",
        "        os.mkdir(datasets_dir)\n",
        "\n",
        "    url = DATASET_URL[dataset_name]\n",
        "    destination = datasets_dir + '/'\n",
        "\n",
        "    # download dataset (.zip) from google drive\n",
        "    path_to_zip = gdown.download(url, output=destination, quiet=False, fuzzy=True)\n",
        "\n",
        "    # unzip\n",
        "    with zipfile.ZipFile(path_to_zip, 'r') as zip:\n",
        "        zip.extractall(destination)\n",
        "\n",
        "    # delete zip file\n",
        "    os.remove(path_to_zip)\n",
        "\n",
        "if not os.path.exists(DATASET_DIR):\n",
        "    download('waifu', datasets_dir='datasets')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdax3PQmIPn7",
        "outputId": "89169c45-59f7-41a2-d34f-b4c137e5de98"
      },
      "outputs": [],
      "source": [
        "# load state\n",
        "if os.path.exists(STATE_FILE_PATH):\n",
        "    print('loading state... (finished!)')\n",
        "    state_file = open(STATE_FILE_PATH, 'rb')\n",
        "    state = pickle.load(state_file)\n",
        "    if 'LATEST_EPOCH' in state:\n",
        "        INITIAL_EPOCH = state['LATEST_EPOCH']\n",
        "    if 'LOSS_G' in state:\n",
        "        LOSS_G = state['LOSS_G']\n",
        "    if 'LOSS_C' in state:\n",
        "        LOSS_C = state['LOSS_C']\n",
        "    if 'FIXED_NOISE' in state:\n",
        "        FIXED_NOISE = state['FIXED_NOISE']\n",
        "    state_file.close()\n",
        "\n",
        "generator = Generator()\n",
        "critic = Critic()\n",
        "wgan_gp = WGAN_GP(generator, critic)\n",
        "\n",
        "latest_cp = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
        "if latest_cp:\n",
        "    wgan_gp.load_weights(latest_cp)\n",
        "    print('loading weight... (finished!)')\n",
        "\n",
        "gen_optimizer = keras.optimizers.legacy.Adam(1e-4, beta_1=0.0, beta_2=0.9)\n",
        "crit_optimizer = keras.optimizers.legacy.Adam(1e-4, beta_1=0.0, beta_2=0.9)\n",
        "\n",
        "# load dataset & normalize to [-1, 1]\n",
        "print('loading dataset...')\n",
        "dataset = keras.utils.image_dataset_from_directory(\n",
        "    directory=DATASET_DIR,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE\n",
        ").map(lambda imgs, _ : tf.cast(imgs, tf.float32) / 127.5 - 1)\n",
        "\n",
        "wgan_gp.compile(gen_optimizer, crit_optimizer)\n",
        "\n",
        "print('start training!')\n",
        "wgan_gp.train(dataset, N_EPOCH, N_CRITIC, FIXED_NOISE)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
